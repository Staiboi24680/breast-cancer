{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72480afd-2f10-4f41-a6d5-3a861ed7088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\staiboi\\anaconda3\\lib\\site-packages (24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000298DB93CA10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000298DB950790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000298DB953950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000298DB960950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000298DB9616D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3292f6e4-7225-4b38-b784-e3770780e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries required\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c348c997-cd47-4e3d-9898-230365bce208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating random images for the \"unknown\" class\n",
    "def generate_noise_images(output_dir, num_images, img_size=(224, 224)):\n",
    "    os.makedirs(output_dir, exist_ok=True);\n",
    "    for i in range(num_images):\n",
    "        noise_img = np.random.rand(*img_size, 3) * 255;\n",
    "        noise_img = noise_img.astype(np.uint8);\n",
    "        cv2.imwrite(os.path.join(output_dir, f\"Unknown_{i}.png\"), noise_img);\n",
    "generate_noise_images(output_dir=\"Unknown\", num_images=1000)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24846f1c-0a4a-4dd8-a1c7-5dde317490bc",
   "metadata": {},
   "source": [
    "### Splitting the dataset into trainning and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70bd29b2-684e-4551-a1fb-7dbb261cb8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2063 images belonging to 4 classes.\n",
      "Found 515 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define image data generators for training and validation with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Use 20% of data for validation\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\STAIBOI\\\\Desktop\\\\New folder (2)\\\\Dataset_BUSI_with_GT',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'C:\\\\Users\\\\STAIBOI\\\\Desktop\\\\New folder (2)\\\\Dataset_BUSI_with_GT',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "890b0869-5de9-422f-8129-348befd116dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Checking if the directory is in the path \n",
    "import os\n",
    "print(os.path.isdir('Dataset_BUSI_with_GT/'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ff03ed-f38e-47a9-b56a-a405940b7732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STAIBOI\\Desktop\\New folder (2)\\Dataset_BUSI_with_GT\n"
     ]
    }
   ],
   "source": [
    "# Checking for the path of the directory of the notebook\n",
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d70b5-1ce9-4cc5-b232-3f80eb963642",
   "metadata": {},
   "source": [
    "### Building the cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b2431ab-9c0e-4ac0-bb23-43b95cdc722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(4, activation='softmax')  # 4 output classes (malignant, benign, normal, unknown)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab81c047-54bf-4f08-aa19-782d2dd6bd73",
   "metadata": {},
   "source": [
    "### Trainning the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11cf634e-ab4c-458c-840b-60b1fba2b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\STAIBOI\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.5817 - loss: 0.9724 - val_accuracy: 0.7981 - val_loss: 0.4674\n",
      "Epoch 2/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - accuracy: 0.7983 - loss: 0.4548 - val_accuracy: 0.8019 - val_loss: 0.4362\n",
      "Epoch 3/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 2s/step - accuracy: 0.7777 - loss: 0.4574 - val_accuracy: 0.7981 - val_loss: 0.4417\n",
      "Epoch 4/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - accuracy: 0.8047 - loss: 0.4363 - val_accuracy: 0.8369 - val_loss: 0.4026\n",
      "Epoch 5/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 2s/step - accuracy: 0.8196 - loss: 0.4244 - val_accuracy: 0.8369 - val_loss: 0.3997\n",
      "Epoch 6/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - accuracy: 0.8273 - loss: 0.3845 - val_accuracy: 0.8369 - val_loss: 0.3798\n",
      "Epoch 7/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.8425 - loss: 0.3605 - val_accuracy: 0.8330 - val_loss: 0.3841\n",
      "Epoch 8/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 3s/step - accuracy: 0.8582 - loss: 0.3322 - val_accuracy: 0.8097 - val_loss: 0.4322\n",
      "Epoch 9/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.8561 - loss: 0.3524 - val_accuracy: 0.8350 - val_loss: 0.3824\n",
      "Epoch 10/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 3s/step - accuracy: 0.8583 - loss: 0.3296 - val_accuracy: 0.8311 - val_loss: 0.3657\n",
      "Epoch 11/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 2s/step - accuracy: 0.8821 - loss: 0.2892 - val_accuracy: 0.8311 - val_loss: 0.3932\n",
      "Epoch 12/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 2s/step - accuracy: 0.8711 - loss: 0.3001 - val_accuracy: 0.8155 - val_loss: 0.4109\n",
      "Epoch 13/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 2s/step - accuracy: 0.8662 - loss: 0.2881 - val_accuracy: 0.8505 - val_loss: 0.3601\n",
      "Epoch 14/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - accuracy: 0.8821 - loss: 0.2777 - val_accuracy: 0.8350 - val_loss: 0.5213\n",
      "Epoch 15/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 2s/step - accuracy: 0.8323 - loss: 0.5828 - val_accuracy: 0.8408 - val_loss: 0.3653\n",
      "Epoch 16/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 2s/step - accuracy: 0.8463 - loss: 0.3586 - val_accuracy: 0.8194 - val_loss: 0.4562\n",
      "Epoch 17/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 2s/step - accuracy: 0.8461 - loss: 0.3376 - val_accuracy: 0.8485 - val_loss: 0.3817\n",
      "Epoch 18/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 2s/step - accuracy: 0.8849 - loss: 0.2833 - val_accuracy: 0.8155 - val_loss: 0.4505\n",
      "Epoch 19/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 2s/step - accuracy: 0.8829 - loss: 0.2954 - val_accuracy: 0.8602 - val_loss: 0.3654\n",
      "Epoch 20/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 2s/step - accuracy: 0.8742 - loss: 0.2804 - val_accuracy: 0.8505 - val_loss: 0.3516\n",
      "Epoch 21/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 3s/step - accuracy: 0.8838 - loss: 0.2778 - val_accuracy: 0.8369 - val_loss: 0.3743\n",
      "Epoch 22/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.8908 - loss: 0.2609 - val_accuracy: 0.8621 - val_loss: 0.3379\n",
      "Epoch 23/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - accuracy: 0.8914 - loss: 0.2532 - val_accuracy: 0.8408 - val_loss: 0.3751\n",
      "Epoch 24/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 3s/step - accuracy: 0.8986 - loss: 0.2237 - val_accuracy: 0.8524 - val_loss: 0.3823\n",
      "Epoch 25/25\n",
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 3s/step - accuracy: 0.8978 - loss: 0.2462 - val_accuracy: 0.8447 - val_loss: 0.3916\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200daba7-9025-415b-8f6f-b6fb1734cfed",
   "metadata": {},
   "source": [
    "### Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "968dad86-480a-413f-8dee-c5ca4e2f149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 696ms/step - accuracy: 0.8666 - loss: 0.3600\n",
      "Test accuracy: 0.8544\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542632d-df10-405e-8e42-67879fcfc6c3",
   "metadata": {},
   "source": [
    "### Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c966578b-66dd-4b79-b090-cd6596370947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('breast_cancer_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ee45218-588b-4a0d-8a83-83db60a2bfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3c9a2898994ca88bf5713f40bf7359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='image/*', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d11bb293aaa40518069927499a07bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# # Load your model\n",
    "# model = load_model('C:\\\\Users\\\\STAIBOI\\\\Desktop\\\\New folder (2)\\\\Dataset_BUSI_with_GT\\\\breast_cancer_classifier.h5')\n",
    "\n",
    "# # Create file uploader widget\n",
    "# file_upload = widgets.FileUpload(accept='image/*', multiple=False)\n",
    "\n",
    "# # Create a button to trigger the prediction\n",
    "# button = widgets.Button(description=\"Predict\")\n",
    "\n",
    "# # Display the widgets\n",
    "# display(file_upload)\n",
    "# display(button)\n",
    "\n",
    "# def on_button_click(b):\n",
    "#     # Ensure a file is uploaded\n",
    "#     if file_upload.value:\n",
    "#         # Load the uploaded image\n",
    "#         img_data = file_upload.value[next(iter(file_upload.value))]\n",
    "#         img = PIL.Image.open(io.BytesIO(img_data['content']))\n",
    "\n",
    "#         # Preprocess the image (assuming the model expects 224x224 input size)\n",
    "#         img = img.resize((224, 224))\n",
    "#         img_array = np.array(img) / 255.0\n",
    "#         img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "#         # Predict the class\n",
    "#         predictions = model.predict(img_array)\n",
    "#         predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "#         print(f\"Predicted class: {predicted_class[0]}\")\n",
    "#     else:\n",
    "#         print(\"Please upload an image.\")\n",
    "\n",
    "# # Link the button to the prediction function\n",
    "# button.on_click(on_button_click)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737f363b-97f8-435b-917b-ffb1585f4649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
